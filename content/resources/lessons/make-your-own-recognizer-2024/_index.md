---
title: Make Your Own Recogniser 2024
weight: 5
---

As part of the 2024 Conference of the Ecological Society of Austalia we are running 
a workshop for building automated call recognisers. The goal of this workshop was for 
each participant to leave with a working call recogniser for a single species-call of 
their choice. It covered some basic theory and practice of building a call recogniser 
based on embeddings produced by a convolutional neural network. 

This is a collaboration between the QUT ecoacoustics group and The developers of the 
Perch embedding model and Agile Modelling workflow from Google Deepmind with support 
from the Australian Research Data Commons.  

This page will be updated closer to the Workshop date, but for now please read over 
the requirements.

<div style="display: flex; gap: 30px; justify-content: space-between; padding: 2em 0em 2em 0em">
   <div style="width: 33%; height: 60px;">
       <img src="/images/ARDC_logo_RGB-250x82.png" alt="Australian Research Data Commons" 
       style="width: 100%; height: 100%; object-fit: contain;">
   </div>
   <div style="width: 33%; height: 60px;">
       <img src="/images/Google_DeepMind_logo.svg" alt="Google Deepmind" style="width: 100%; 
       height: 100%; object-fit: contain;">
   </div>
   <div style="width: 33%; height: 60px;">
       <img src="/images/QUT-logo-–-Blue-–-RGB-–-PNG-110x110.png" alt="Australian 
       Data Research Commons" style="width: 100%; height: 100%; object-fit: contain;">
   </div>
</div>
