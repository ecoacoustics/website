---
title: Make Your Own Recogniser
weight: 5
---

As part of the 2025 Australian Acoustic Society Conference we are running 
a workshop for building automated call recognisers. The goal of this workshop is for 
each participant to leave with a working call recogniser for a single species-call of 
their choice. It covers some basic theory of convolutional neural networks, embeddings and 
embedding based classifiers. We are using [Perch](https://deepmind.google/discover/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/) embeddings, and [Ecosounds](https://www.ecosounds.org/) for serving audio and verifying detections. 

This workshop is run by QUT ecoacoustics group with support from the Australian Research Data Commons,
and from Google Deepmind, the developers of the Perch embedding model and Agile Modelling workflow.


<div style="display: flex; gap: 30px; justify-content: space-between; padding: 2em 0em 2em 0em">
   <div style="width: 33%; height: 60px;">
       <img src="/images/ARDC_logo_RGB-250x82.png" alt="Australian Research Data Commons" 
       style="width: 100%; height: 100%; box-shadow: none; object-fit: contain;">
   </div>
   <div style="width: 33%; height: 60px;">
       <img src="/images/Google_DeepMind_logo.svg" alt="Google Deepmind" style="width: 100%; 
       height: 100%; box-shadow: none; object-fit: contain;">
   </div>
   <div style="width: 33%; height: 60px;">
       <img src="/images/QUT-logo-–-Blue-–-RGB-–-PNG-110x110.png" alt="Australian 
       Data Research Commons" style="width: 100%; height: 100%; box-shadow: none; object-fit: contain;">
   </div>
</div>


