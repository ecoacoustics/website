---
title: Make Your Own Recogniser
weight: 5
---

As part of the 2024 Conference of the Ecological Society of Australia, we ran a workshop on building automated call recognisers. The goal of this workshop was for each participant to leave with a working call recogniser for a single species call of their choice. It covered some fundamental theories and practices of building a call recogniser based on embeddings produced by a convolutional neural network. This workshop  was a collaboration between the Open Ecoacoustics group and the developers of the Perch embedding model and Agile Modelling workflow from Google Deepmind with support from the Australian Research Data Commons.We have collected some resources based on this workshop here.

To get started, please head to the [requirements]({{< ref "./requirements" >}}).

<div style="display: flex; gap: 30px; justify-content: space-between; padding: 2em 0em 2em 0em">
   <div style="width: 33%; height: 60px;">
       <img src="/images/ARDC_logo_RGB-250x82.png" alt="Australian Research Data Commons"
       style="width: 100%; height: 100%; box-shadow: none; object-fit: contain;">
   </div>
   <div style="width: 33%; height: 60px;">
       <img src="/images/Google_DeepMind_logo.svg" alt="Google Deepmind" style="width: 100%;
       height: 100%; box-shadow: none; object-fit: contain;">
   </div>
   <div style="width: 33%; height: 60px;">
       <img src="/images/QUT-logo-–-Blue-–-RGB-–-PNG-110x110.png" alt="Australian
       Data Research Commons" style="width: 100%; height: 100%; box-shadow: none; object-fit: contain;">
   </div>
</div>


Note: This workshop replaces the deprecated [2022 workshop](https://github.com/ecoacoustics/website/tree/cf422761360302ac9efed87bfa5a4d2716204bf9/content/resources/lessons/make-your-own-recognizer).
